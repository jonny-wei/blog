(window.webpackJsonp=window.webpackJsonp||[]).push([[145],{446:function(s,t,n){"use strict";n.r(t);var a=n(6),e=Object(a.a)({},(function(){var s=this,t=s._self._c;return t("ContentSlotsDistributor",{attrs:{"slot-key":s.$parent.slotKey}},[t("h1",{attrs:{id:"react-diff-算法"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#react-diff-算法"}},[s._v("#")]),s._v(" React Diff 算法")]),s._v(" "),t("p",[s._v("在 React 中，通过 React.createElement 也能生成一个虚拟 DOM 节点（ReactElement）。在 React15 及以前，采用了递归的方式创建虚拟 DOM，递归过程是不能中断的。如果组件树的层级很深，递归会占用线程很多时间，造成卡顿。React16 将递归的无法中断的更新重构为异步的可中断更新，推出了新的 Fiber 架构。")]),s._v(" "),t("p",[s._v("原本的 ReactElement 只有 children，在中断恢复时，无法找到其兄弟节点和父节点，无法从断点处继续完成渲染工作。而 fiber 节点上能访问到父节点、子节点、兄弟节点，所以即使渲染被打断了，也可以恢复查找未处理的节点。因此，React 需要先生成 ReactElement，再生成 fiber，最后才将变更映射到真实 DOM 节点。Vue 与 React 不同，它通过递归的形式生成整个虚拟 DOM 树，在 diff 的同时会对 DOM 做变更。")]),s._v(" "),t("p",[s._v("React 采用了双缓存的技术，在 React 中最多会存在两颗 fiber 树，当前屏幕上显示内容对应的 fiber 树称为 current fiber 树，正在内存中构建的 fiber 树称为 workInProgress fiber 树。当 workInProgress fiber 树构建并渲染到页面上后，应用根节点的 current 指针指向 workInProgress Fiber 树，此时 workInProgress Fiber 树就变为 current Fiber 树。")]),s._v(" "),t("p",[s._v("React 的更新会经历两个阶段：render 阶段 和 commit 阶段。render 阶段是可中断的，commit 阶段是不可中断的。")]),s._v(" "),t("ul",[t("li",[t("p",[s._v("render 阶段会生成 fiber 树，所谓的 diff 就会发生在这个阶段。React 通过深度优先遍历来生成 fiber 树，整个过程与递归是类似的，因此生成 fiber 树的过程又可以分为「递」阶段和「归」阶段。")])]),s._v(" "),t("li",[t("p",[s._v("commit 阶段主要执行各种 DOM 操作、生命周期钩子、某些 hook 等。")])])]),s._v(" "),t("p",[s._v("因此，diff 阶段不会直接变更 DOM，而是留到 commit 阶段再做变更。")]),s._v(" "),t("p",[s._v("React 如何知道哪些 DOM 节点需要被更新呢？")]),s._v(" "),t("p",[s._v("在"),t("code",[s._v("render")]),s._v("阶段的"),t("code",[s._v("beginWork")]),s._v("函数中，会将上次更新产生的 Fiber 节点与本次更新的 JSX 对象（对应"),t("code",[s._v("ClassComponent")]),s._v("的"),t("code",[s._v("this.render")]),s._v("方法返回值，或者"),t("code",[s._v("FunctionComponent")]),s._v("执行的返回值）进行比较。根据比较的结果生成"),t("code",[s._v("workInProgress Fiber")]),s._v("，即本次更新的 Fiber 节点。即，"),t("strong",[s._v("React 将上次更新的结果与本次更新的值比较，只将变化的部分体现在 DOM 上")]),s._v("。这个比较的过程，就是 Diff。")]),s._v(" "),t("p",[s._v("由于 Diff 操作本身也会带来性能损耗，React文档中提到，即使在最前沿的算法中，将前后两棵树完全比对的算法的复杂程度为 O(n^3 )，其中 n 是树中元素的数量。")]),s._v(" "),t("div",{staticClass:"custom-block tip"},[t("p",{staticClass:"custom-block-title"},[s._v("O(n³)  由来")]),s._v(" "),t("p",[s._v("关于 O(n³) 的由来。由于左树中任意节点都可能出现在右树，所以必须在对左树深度遍历的同时，对右树进行深度遍历，找到每个节点的对应关系，这里的时间复杂度是 O(n²)，之后需要对树的各节点进行增删移的操作，这个过程简单可以理解为加了一层遍历循环，因此再乘一个 n。")])]),s._v(" "),t("p",[s._v("为了降低算法复杂度，React 的 diff 会预设三个限制：")]),s._v(" "),t("ul",[t("li",[s._v("Tree Diff（树策略）: 只对同级元素进行Diff。如果一个DOM节点在前后两次更新中跨越了层级，那么 React 不会尝试复用他。 因为，Web UI 中 DOM 节点跨层级的移动操作特别少，可以忽略不计。")]),s._v(" "),t("li",[s._v("Component Diff（组件策略）: 拥有相同类的两个组件将会生成相似的树形结构，拥有不同类的两个组件将会生成不同的树形结构")]),s._v(" "),t("li",[s._v("Element Diff（元素策略）：对于同一层级的一组子节点，它们可以通过唯一 id 进行区分。开发者可以通过 key 属性来暗示哪些子元素在不同的渲染下能保持稳定。")])]),s._v(" "),t("p",[s._v("React 进行 "),t("code",[s._v("tree diff")]),s._v("、"),t("code",[s._v("component diff")]),s._v(" 和 "),t("code",[s._v("element diff")]),s._v("进行算法优化是基于上面三个前提策略。事实证明上面的三个前提策略是非常有效的。")]),s._v(" "),t("h2",{attrs:{id:"diff-入口"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#diff-入口"}},[s._v("#")]),s._v(" Diff 入口")]),s._v(" "),t("div",{staticClass:"language-js line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-js"}},[t("code",[t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("function")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("reconcileChildFibers")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("\n    "),t("span",{pre:!0,attrs:{class:"token parameter"}},[t("span",{pre:!0,attrs:{class:"token literal-property property"}},[s._v("returnFiber")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v(":")]),s._v(" Fiber"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n    "),t("span",{pre:!0,attrs:{class:"token literal-property property"}},[s._v("currentFirstChild")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v(":")]),s._v(" Fiber "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("|")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("null")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n    "),t("span",{pre:!0,attrs:{class:"token literal-property property"}},[s._v("newChild")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v(":")]),s._v(" any"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n    "),t("span",{pre:!0,attrs:{class:"token literal-property property"}},[s._v("lanes")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v(":")]),s._v(" Lanes"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")])]),s._v("\n  "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v(":")]),s._v(" Fiber "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("|")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("null")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n    "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("// ...")]),s._v("\n\n    "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("// 判断 newChild 类型")]),s._v("\n    "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("const")]),s._v(" isObject "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("typeof")]),s._v(" newChild "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("===")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'object'")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("&&")]),s._v(" newChild "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("!==")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("null")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n\n    "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("// object类型，可能是 REACT_ELEMENT_TYPE 或 REACT_PORTAL_TYPE 等  ")]),s._v("\n    "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("if")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("isObject"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n      "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("switch")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("newChild"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("$$"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("typeof")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n        "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("case")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token constant"}},[s._v("REACT_ELEMENT_TYPE")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v(":")]),s._v("\n          "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("// 调用 reconcileSingleElement 处理")]),s._v("\n          "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("return")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("placeSingleChild")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("\n            "),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("reconcileSingleElement")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("\n              returnFiber"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n              currentFirstChild"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n              newChild"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n              lanes"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n            "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n          "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n        "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("case")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token constant"}},[s._v("REACT_PORTAL_TYPE")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v(":")]),s._v("\n          "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("// 调用 reconcileSinglePortal 处理    ")]),s._v("\n          "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("// ....")]),s._v("\n        "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("case")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token constant"}},[s._v("REACT_LAZY_TYPE")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v(":")]),s._v("\n          "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("// 调用 reconcileChildFibers 处理    ")]),s._v("\n          "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("// ....")]),s._v("\n      "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n    "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n\n    "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("// newChild 是字符串或数字 调用 reconcileSingleTextNode 处理   ")]),s._v("\n    "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("if")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("typeof")]),s._v(" newChild "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("===")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'string'")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("||")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("typeof")]),s._v(" newChild "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("===")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'number'")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n      "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("return")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("placeSingleChild")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("\n        "),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("reconcileSingleTextNode")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("\n          returnFiber"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n          currentFirstChild"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n          "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("''")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("+")]),s._v(" newChild"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n          lanes"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n        "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n      "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n    "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n\n    "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("// newChild 是数组 调用 reconcileChildrenArray 处理")]),s._v("\n    "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("if")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("isArray")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("newChild"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n      "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("return")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("reconcileChildrenArray")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("\n        returnFiber"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n        currentFirstChild"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n        newChild"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n        lanes"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n      "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n    "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("// newChild 迭代器 reconcileChildrenIterator 处理")]),s._v("\n    "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("if")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("getIteratorFn")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("newChild"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n      "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("return")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("reconcileChildrenIterator")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("\n        returnFiber"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n        currentFirstChild"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n        newChild"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n        lanes"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n      "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n    "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n    "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("// ....    ")]),s._v("\n\n    "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("// 以上都没有命中，删除节点")]),s._v("\n    "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("return")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("deleteRemainingChildren")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("returnFiber"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" currentFirstChild"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n")])]),s._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[s._v("1")]),t("br"),t("span",{staticClass:"line-number"},[s._v("2")]),t("br"),t("span",{staticClass:"line-number"},[s._v("3")]),t("br"),t("span",{staticClass:"line-number"},[s._v("4")]),t("br"),t("span",{staticClass:"line-number"},[s._v("5")]),t("br"),t("span",{staticClass:"line-number"},[s._v("6")]),t("br"),t("span",{staticClass:"line-number"},[s._v("7")]),t("br"),t("span",{staticClass:"line-number"},[s._v("8")]),t("br"),t("span",{staticClass:"line-number"},[s._v("9")]),t("br"),t("span",{staticClass:"line-number"},[s._v("10")]),t("br"),t("span",{staticClass:"line-number"},[s._v("11")]),t("br"),t("span",{staticClass:"line-number"},[s._v("12")]),t("br"),t("span",{staticClass:"line-number"},[s._v("13")]),t("br"),t("span",{staticClass:"line-number"},[s._v("14")]),t("br"),t("span",{staticClass:"line-number"},[s._v("15")]),t("br"),t("span",{staticClass:"line-number"},[s._v("16")]),t("br"),t("span",{staticClass:"line-number"},[s._v("17")]),t("br"),t("span",{staticClass:"line-number"},[s._v("18")]),t("br"),t("span",{staticClass:"line-number"},[s._v("19")]),t("br"),t("span",{staticClass:"line-number"},[s._v("20")]),t("br"),t("span",{staticClass:"line-number"},[s._v("21")]),t("br"),t("span",{staticClass:"line-number"},[s._v("22")]),t("br"),t("span",{staticClass:"line-number"},[s._v("23")]),t("br"),t("span",{staticClass:"line-number"},[s._v("24")]),t("br"),t("span",{staticClass:"line-number"},[s._v("25")]),t("br"),t("span",{staticClass:"line-number"},[s._v("26")]),t("br"),t("span",{staticClass:"line-number"},[s._v("27")]),t("br"),t("span",{staticClass:"line-number"},[s._v("28")]),t("br"),t("span",{staticClass:"line-number"},[s._v("29")]),t("br"),t("span",{staticClass:"line-number"},[s._v("30")]),t("br"),t("span",{staticClass:"line-number"},[s._v("31")]),t("br"),t("span",{staticClass:"line-number"},[s._v("32")]),t("br"),t("span",{staticClass:"line-number"},[s._v("33")]),t("br"),t("span",{staticClass:"line-number"},[s._v("34")]),t("br"),t("span",{staticClass:"line-number"},[s._v("35")]),t("br"),t("span",{staticClass:"line-number"},[s._v("36")]),t("br"),t("span",{staticClass:"line-number"},[s._v("37")]),t("br"),t("span",{staticClass:"line-number"},[s._v("38")]),t("br"),t("span",{staticClass:"line-number"},[s._v("39")]),t("br"),t("span",{staticClass:"line-number"},[s._v("40")]),t("br"),t("span",{staticClass:"line-number"},[s._v("41")]),t("br"),t("span",{staticClass:"line-number"},[s._v("42")]),t("br"),t("span",{staticClass:"line-number"},[s._v("43")]),t("br"),t("span",{staticClass:"line-number"},[s._v("44")]),t("br"),t("span",{staticClass:"line-number"},[s._v("45")]),t("br"),t("span",{staticClass:"line-number"},[s._v("46")]),t("br"),t("span",{staticClass:"line-number"},[s._v("47")]),t("br"),t("span",{staticClass:"line-number"},[s._v("48")]),t("br"),t("span",{staticClass:"line-number"},[s._v("49")]),t("br"),t("span",{staticClass:"line-number"},[s._v("50")]),t("br"),t("span",{staticClass:"line-number"},[s._v("51")]),t("br"),t("span",{staticClass:"line-number"},[s._v("52")]),t("br"),t("span",{staticClass:"line-number"},[s._v("53")]),t("br"),t("span",{staticClass:"line-number"},[s._v("54")]),t("br"),t("span",{staticClass:"line-number"},[s._v("55")]),t("br"),t("span",{staticClass:"line-number"},[s._v("56")]),t("br"),t("span",{staticClass:"line-number"},[s._v("57")]),t("br"),t("span",{staticClass:"line-number"},[s._v("58")]),t("br"),t("span",{staticClass:"line-number"},[s._v("59")]),t("br"),t("span",{staticClass:"line-number"},[s._v("60")]),t("br"),t("span",{staticClass:"line-number"},[s._v("61")]),t("br"),t("span",{staticClass:"line-number"},[s._v("62")]),t("br"),t("span",{staticClass:"line-number"},[s._v("63")]),t("br"),t("span",{staticClass:"line-number"},[s._v("64")]),t("br"),t("span",{staticClass:"line-number"},[s._v("65")]),t("br"),t("span",{staticClass:"line-number"},[s._v("66")]),t("br"),t("span",{staticClass:"line-number"},[s._v("67")]),t("br"),t("span",{staticClass:"line-number"},[s._v("68")]),t("br")])]),t("p",[s._v("我们可以从同级的节点数量将 Diff 分为两类：")]),s._v(" "),t("ul",[t("li",[t("p",[s._v("单节点条件：当"),t("code",[s._v("newChild")]),s._v("类型为"),t("code",[s._v("object")]),s._v("、"),t("code",[s._v("number")]),s._v("、"),t("code",[s._v("string")]),s._v("，代表同级只有一个节点")])]),s._v(" "),t("li",[t("p",[s._v("多节点条件：当"),t("code",[s._v("newChild")]),s._v("类型为"),t("code",[s._v("Array")]),s._v("，同级有多个节点")])])]),s._v(" "),t("h2",{attrs:{id:"单节点-diff"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#单节点-diff"}},[s._v("#")]),s._v(" 单节点 Diff")]),s._v(" "),t("p",[s._v("对于单个节点，当"),t("code",[s._v("newChild")]),s._v("类型为"),t("code",[s._v("object")]),s._v("、"),t("code",[s._v("number")]),s._v("、"),t("code",[s._v("string")]),s._v("，代表同级只有一个节点，会进入"),t("code",[s._v("reconcileSingleElement")])]),s._v(" "),t("div",{staticClass:"language-js line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-js"}},[t("code",[t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("function")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("reconcileSingleElement")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("\n    "),t("span",{pre:!0,attrs:{class:"token parameter"}},[t("span",{pre:!0,attrs:{class:"token literal-property property"}},[s._v("returnFiber")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v(":")]),s._v(" Fiber"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n    "),t("span",{pre:!0,attrs:{class:"token literal-property property"}},[s._v("currentFirstChild")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v(":")]),s._v(" Fiber "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("|")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("null")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n    "),t("span",{pre:!0,attrs:{class:"token literal-property property"}},[s._v("element")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v(":")]),s._v(" ReactElement"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n    "),t("span",{pre:!0,attrs:{class:"token literal-property property"}},[s._v("lanes")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v(":")]),s._v(" Lanes"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")])]),s._v("\n  "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v(":")]),s._v(" Fiber "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n    "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("const")]),s._v(" key "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" element"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("key"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n    "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("let")]),s._v(" child "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" currentFirstChild"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n        \n    "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("// 首先判断是否存在对应 DOM 节点")]),s._v("\n    "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("while")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("child "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("!==")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("null")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n      "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("// 上一次更新存在 DOM 节点，接下来判断是否可复用")]),s._v("\n      "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("// 首先比较 key 是否相同  ")]),s._v("\n      "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("if")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("child"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("key "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("===")]),s._v(" key"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n        "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("// key 相同，接下来比较 type 是否相同")]),s._v("\n        "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("switch")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("child"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("tag"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n          "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("case")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token literal-property property"}},[s._v("Fragment")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v(":")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("// ...")]),s._v("\n          "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("case")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token literal-property property"}},[s._v("Block")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v(":")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("// ...")]),s._v("\n          "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("default")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v(":")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n            "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("if")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("child"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("elementType "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("===")]),s._v(" element"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("type "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n              "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("// 情况一：key 和 type 都相同则表示可以复用 返回复用的 fiber")]),s._v("\n              "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("return")]),s._v(" existing"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n            "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n            "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("// type 不同则跳出 switch")]),s._v("\n            "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("break")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n          "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n        "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n        "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("// Didn't match.")]),s._v("\n        "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("// 情况二：key 相同但是 type 不同 将该 fiber 及其兄弟 fiber 标记为删除")]),s._v("\n        "),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("deleteRemainingChildren")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("returnFiber"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" child"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n        "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("break")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n      "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("else")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n        "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("// 情况三：key 不同，Type也不同，将该 fiber 标记为删除")]),s._v("\n        "),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("deleteChild")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("returnFiber"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" child"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n      "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n      child "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" child"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("sibling"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n    "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("// 创建新 fiber")]),s._v("\n    "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("if")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("element"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("type "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("===")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token constant"}},[s._v("REACT_FRAGMENT_TYPE")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n      "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("const")]),s._v(" created "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("createFiberFromFragment")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("\n        element"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("props"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("children"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n        returnFiber"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("mode"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n        lanes"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n        element"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("key"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n      "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n      created"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("return "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" returnFiber"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n      "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("return")]),s._v(" created"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n    "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("else")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n      "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("const")]),s._v(" created "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("createFiberFromElement")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("element"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" returnFiber"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("mode"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" lanes"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n      created"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("ref "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("coerceRef")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("returnFiber"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" currentFirstChild"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" element"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n      created"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("return "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" returnFiber"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n      "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("return")]),s._v(" created"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n    "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n  "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n")])]),s._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[s._v("1")]),t("br"),t("span",{staticClass:"line-number"},[s._v("2")]),t("br"),t("span",{staticClass:"line-number"},[s._v("3")]),t("br"),t("span",{staticClass:"line-number"},[s._v("4")]),t("br"),t("span",{staticClass:"line-number"},[s._v("5")]),t("br"),t("span",{staticClass:"line-number"},[s._v("6")]),t("br"),t("span",{staticClass:"line-number"},[s._v("7")]),t("br"),t("span",{staticClass:"line-number"},[s._v("8")]),t("br"),t("span",{staticClass:"line-number"},[s._v("9")]),t("br"),t("span",{staticClass:"line-number"},[s._v("10")]),t("br"),t("span",{staticClass:"line-number"},[s._v("11")]),t("br"),t("span",{staticClass:"line-number"},[s._v("12")]),t("br"),t("span",{staticClass:"line-number"},[s._v("13")]),t("br"),t("span",{staticClass:"line-number"},[s._v("14")]),t("br"),t("span",{staticClass:"line-number"},[s._v("15")]),t("br"),t("span",{staticClass:"line-number"},[s._v("16")]),t("br"),t("span",{staticClass:"line-number"},[s._v("17")]),t("br"),t("span",{staticClass:"line-number"},[s._v("18")]),t("br"),t("span",{staticClass:"line-number"},[s._v("19")]),t("br"),t("span",{staticClass:"line-number"},[s._v("20")]),t("br"),t("span",{staticClass:"line-number"},[s._v("21")]),t("br"),t("span",{staticClass:"line-number"},[s._v("22")]),t("br"),t("span",{staticClass:"line-number"},[s._v("23")]),t("br"),t("span",{staticClass:"line-number"},[s._v("24")]),t("br"),t("span",{staticClass:"line-number"},[s._v("25")]),t("br"),t("span",{staticClass:"line-number"},[s._v("26")]),t("br"),t("span",{staticClass:"line-number"},[s._v("27")]),t("br"),t("span",{staticClass:"line-number"},[s._v("28")]),t("br"),t("span",{staticClass:"line-number"},[s._v("29")]),t("br"),t("span",{staticClass:"line-number"},[s._v("30")]),t("br"),t("span",{staticClass:"line-number"},[s._v("31")]),t("br"),t("span",{staticClass:"line-number"},[s._v("32")]),t("br"),t("span",{staticClass:"line-number"},[s._v("33")]),t("br"),t("span",{staticClass:"line-number"},[s._v("34")]),t("br"),t("span",{staticClass:"line-number"},[s._v("35")]),t("br"),t("span",{staticClass:"line-number"},[s._v("36")]),t("br"),t("span",{staticClass:"line-number"},[s._v("37")]),t("br"),t("span",{staticClass:"line-number"},[s._v("38")]),t("br"),t("span",{staticClass:"line-number"},[s._v("39")]),t("br"),t("span",{staticClass:"line-number"},[s._v("40")]),t("br"),t("span",{staticClass:"line-number"},[s._v("41")]),t("br"),t("span",{staticClass:"line-number"},[s._v("42")]),t("br"),t("span",{staticClass:"line-number"},[s._v("43")]),t("br"),t("span",{staticClass:"line-number"},[s._v("44")]),t("br"),t("span",{staticClass:"line-number"},[s._v("45")]),t("br"),t("span",{staticClass:"line-number"},[s._v("46")]),t("br"),t("span",{staticClass:"line-number"},[s._v("47")]),t("br"),t("span",{staticClass:"line-number"},[s._v("48")]),t("br"),t("span",{staticClass:"line-number"},[s._v("49")]),t("br"),t("span",{staticClass:"line-number"},[s._v("50")]),t("br"),t("span",{staticClass:"line-number"},[s._v("51")]),t("br"),t("span",{staticClass:"line-number"},[s._v("52")]),t("br"),t("span",{staticClass:"line-number"},[s._v("53")]),t("br"),t("span",{staticClass:"line-number"},[s._v("54")]),t("br")])]),t("p",[s._v("React 通过先判断 "),t("code",[s._v("key")]),s._v(" 是否相同，如果 "),t("code",[s._v("key")]),s._v(" 相同则判断 "),t("code",[s._v("type")]),s._v(" 是否相同，只有都相同时一个 "),t("code",[s._v("DOM节点")]),s._v(" 才能复用。")]),s._v(" "),t("ul",[t("li",[s._v("当"),t("code",[s._v("child !== null")]),s._v("且"),t("code",[s._v("key相同")]),s._v("且"),t("code",[s._v("type不同")]),s._v("时执行"),t("code",[s._v("deleteRemainingChildren")]),s._v("将"),t("code",[s._v("child")]),s._v("及其兄弟"),t("code",[s._v("fiber")]),s._v("都标记删除。")]),s._v(" "),t("li",[s._v("当"),t("code",[s._v("child !== null")]),s._v("且"),t("code",[s._v("key不同")]),s._v("时仅将"),t("code",[s._v("child")]),s._v("标记删除。")])]),s._v(" "),t("h4",{attrs:{id:"小结"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#小结"}},[s._v("#")]),s._v(" 小结")]),s._v(" "),t("ul",[t("li",[s._v("单节点条件："),t("code",[s._v("newChild")]),s._v(" 类型为 "),t("code",[s._v("object")]),s._v("、"),t("code",[s._v("number")]),s._v("、"),t("code",[s._v("string")]),s._v("，代表同级只有一个节点。")]),s._v(" "),t("li",[s._v("单节点复用条件：key 和 type 都相等，否则不可复用节点。\n"),t("ul",[t("li",[s._v("key 相同："),t("code",[s._v("child.key === key")]),s._v("。没有设置 key 则为 null。新旧节点 key 都为 null，也认为 key 相同。")]),s._v(" "),t("li",[s._v("type 相同："),t("code",[s._v("child.elementType === element.type")])])])]),s._v(" "),t("li",[s._v("单节点 diff 规则：child 存在的情况下（有节点），先判断 "),t("code",[s._v("key")]),s._v(" 是否相同，如果 "),t("code",[s._v("key")]),s._v(" 相同则判断 "),t("code",[s._v("type")]),s._v(" 是否相同，只有都相同时一个 "),t("code",[s._v("DOM节点")]),s._v(" 才能复用。\n"),t("ul",[t("li",[s._v("key 相同 & type 相同：可以复用 返回复用的 fiber")]),s._v(" "),t("li",[s._v("key 相同 & type 不同：将该 fiber 及其兄弟 fiber 标记为删除")]),s._v(" "),t("li",[s._v("key 不同：将该 fiber 标记为删除")])])]),s._v(" "),t("li",[s._v("没有节点，则直接新建")])]),s._v(" "),t("h2",{attrs:{id:"多节点-diff"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#多节点-diff"}},[s._v("#")]),s._v(" 多节点 Diff")]),s._v(" "),t("p",[s._v("React 每次更新时，会将新的 ReactElement（即 React.createElement() 的返回值）与旧的 fiber 树作对比，比较出它们的差异后，构建出新的 fiber 树，因此"),t("strong",[s._v("多节点的")]),s._v(" "),t("strong",[s._v("diff")]),s._v(" "),t("strong",[s._v("实际上是用 fiber（旧子节点）和 ReactElement 数组（新子节点）进行对比")]),s._v("。多节点 DIff 无非以下情况：")]),s._v(" "),t("ul",[t("li",[s._v("节点更新（属性、类型）")]),s._v(" "),t("li",[s._v("节点新增或删除")]),s._v(" "),t("li",[s._v("节点位置变化")])]),s._v(" "),t("p",[s._v("在日常开发中，相较于"),t("code",[s._v("新增")]),s._v("和"),t("code",[s._v("删除")]),s._v("，"),t("code",[s._v("更新")]),s._v("组件发生的频率更高。所以"),t("code",[s._v("Diff")]),s._v("会优先判断当前节点是否属于"),t("code",[s._v("更新")]),s._v("。")]),s._v(" "),t("p",[t("code",[s._v("多节点 Diff算法")]),s._v("的整体逻辑会经历两轮遍历：")]),s._v(" "),t("ul",[t("li",[s._v("第一轮遍历：处理"),t("code",[s._v("更新")]),s._v("的节点。")]),s._v(" "),t("li",[s._v("第二轮遍历：处理剩下的不属于"),t("code",[s._v("更新")]),s._v("的节点。")])]),s._v(" "),t("div",{staticClass:"language-js line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-js"}},[t("code",[t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("function")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("reconcileChildrenArray")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("\n    "),t("span",{pre:!0,attrs:{class:"token literal-property property"}},[s._v("returnFiber")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v(":")]),s._v(" Fiber"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n    "),t("span",{pre:!0,attrs:{class:"token literal-property property"}},[s._v("currentFirstChild")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v(":")]),s._v(" Fiber "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("|")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("null")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n    "),t("span",{pre:!0,attrs:{class:"token literal-property property"}},[s._v("newChildren")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v(":")]),s._v(" Array"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("<")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("*")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v(">")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("// 新节点")]),s._v("\n    "),t("span",{pre:!0,attrs:{class:"token literal-property property"}},[s._v("lanes")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v(":")]),s._v(" Lanes"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n  "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v(":")]),s._v(" Fiber "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("|")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("null")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n    "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("// 列表中使用 React element 数据更新了属性的第一个 Fiber 节点")]),s._v("\n    "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("let")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token literal-property property"}},[s._v("resultingFirstChild")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v(":")]),s._v(" Fiber "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("|")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("null")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("null")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n    "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("// 上一个更新了属性的 Fiber 节点，用以列表中兄弟节点的相互关联")]),s._v("\n    "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("let")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token literal-property property"}},[s._v("previousNewFiber")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v(":")]),s._v(" Fiber "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("|")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("null")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("null")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v(" \n    "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("// current 树上的列表中的第一个Fiber节点")]),s._v("\n    "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("let")]),s._v(" oldFiber "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" currentFirstChild"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v(" \n    "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("// 上一个元素移动位置的下标    ")]),s._v("\n    "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("let")]),s._v(" lastPlacedIndex "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v(" \n    "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("// 遍历 React element 树的下标    ")]),s._v("\n    "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("let")]),s._v(" newIdx "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v(" \n    "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("// current 树上的列表中元素的兄弟节点    ")]),s._v("\n    "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("let")]),s._v(" nextOldFiber "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("null")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v(" \n        \n    "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("// 第一轮遍历：这个 for 循环的作用是剔除没有变化的节点，并对节点进行更新和重用")]),s._v("\n    "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("// 当检查到尾部有新增节点时，oldFiber 为 null，则会跳出循环，")]),s._v("\n    "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("// 然后创建新的 Fiber 插入到尾部，不需要与其它节点进行对比")]),s._v("\n    "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("// 当有新节点想在中间插入，newFiber 则为 null，则会跳出循环，然后需要移动节点位置进行排序")]),s._v("\n    "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("for")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v(" oldFiber "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("!==")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("null")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("&&")]),s._v(" newIdx "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("<")]),s._v(" newChildren"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("length"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v(" newIdx"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("++")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n      "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("if")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("oldFiber"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("index "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v(">")]),s._v(" newIdx"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n        nextOldFiber "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" oldFiber"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n        oldFiber "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("null")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n      "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("else")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n        nextOldFiber "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" oldFiber"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("sibling"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n      "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n      "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("// 判断旧 Fiber 节点上的 key 与 React element 上的 key 属性是否相等")]),s._v("\n      "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("// key 相等，则会使用 React element 的数据更新 Fiber 节点上的属性")]),s._v("\n      "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("// key 不相等，则会返回 null")]),s._v("\n      "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("const")]),s._v(" newFiber "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("updateSlot")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("\n        returnFiber"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n        oldFiber"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n        newChildren"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),s._v("newIdx"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("// 遍历 newChildren")]),s._v("\n        lanes"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n      "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n      "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("// 发现有元素的 key 属性有变化，说明不是更新场景，则会跳出 for 循环")]),s._v("\n      "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("if")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("newFiber "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("===")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("null")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n        "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("if")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("oldFiber "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("===")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("null")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n          oldFiber "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" nextOldFiber"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n        "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n        "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("break")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n      "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n      "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("if")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("shouldTrackSideEffects"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n        "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("if")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("oldFiber "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("&&")]),s._v(" newFiber"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("alternate "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("===")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("null")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n          "),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("deleteChild")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("returnFiber"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" oldFiber"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n        "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n      "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n      "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("// 将 newIdx 赋值给 workInProgress 树上的 Fiber 节点的 index 属性，代表当前元素在列表中的位置（下标）")]),s._v("\n      "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("// 判断 current 树上元素的 Index 是否小于 lastPlacedIndex，是则表示该元素需要移动位置，否则表示不需要移动位置")]),s._v("\n      lastPlacedIndex "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("placeChild")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("newFiber"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" lastPlacedIndex"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" newIdx"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n      "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("if")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("previousNewFiber "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("===")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("null")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n        resultingFirstChild "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" newFiber"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n      "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("else")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n        "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("// 将更新了属性的兄弟 Fiber 节点进行关联")]),s._v("\n        previousNewFiber"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("sibling "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" newFiber"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n      "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n      previousNewFiber "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" newFiber"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n      oldFiber "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" nextOldFiber"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n    "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n    "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("// 新的子节点已经遍历完成，如果还有剩下的节点，表示 current 树上有，")]),s._v("\n    "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("// 但是 workInProgress 树上没有的节点，需要全部删除")]),s._v("\n    "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("if")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("newIdx "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("===")]),s._v(" newChildren"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("length"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n      "),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("deleteRemainingChildren")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("returnFiber"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" oldFiber"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n      "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("return")]),s._v(" resultingFirstChild"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n    "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n    "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("// 节点新增，不需要与旧节点对比，直接创建新增")]),s._v("\n    "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("if")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("oldFiber "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("===")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("null")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n      "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("for")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v(" newIdx "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("<")]),s._v(" newChildren"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("length"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v(" newIdx"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("++")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n        "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("const")]),s._v(" newFiber "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("createChild")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("returnFiber"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" newChildren"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),s._v("newIdx"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" lanes"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n        "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("if")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("newFiber "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("===")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("null")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n          "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("continue")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n        "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n        lastPlacedIndex "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("placeChild")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("newFiber"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" lastPlacedIndex"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" newIdx"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n        "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("if")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("previousNewFiber "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("===")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("null")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n          resultingFirstChild "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" newFiber"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n        "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("else")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n          previousNewFiber"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("sibling "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" newFiber"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n        "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n        previousNewFiber "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" newFiber"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n      "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n      "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("return")]),s._v(" resultingFirstChild"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n    "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n\n    "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("// 将 current 树上的列表中还未对比的元素添加进 Map 对象中")]),s._v("\n    "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("// 下面的 for 循环会根据 key 取出 Map 中对应的旧的 Fiber 与 React element 做类型的比较")]),s._v("\n    "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("// 如果类型相同则更新 Fiber 属性，不同，则会根据 React element 重新创建一个新的 Fiber 做插入操作")]),s._v("\n    "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("const")]),s._v(" existingChildren "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("mapRemainingChildren")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("returnFiber"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" oldFiber"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n\n    "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("// 节点移动")]),s._v("\n    "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("for")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v(" newIdx "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("<")]),s._v(" newChildren"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("length"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v(" newIdx"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("++")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n      "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("// 根据 key 取出 Map 中对应的旧的 Fiber 与 React element 做类型的比较")]),s._v("\n      "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("// 如果类型相同则使用 React element 的数据更新 Fiber 节点上的属性进行重用")]),s._v("\n      "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("// 不同，则会根据 React element 的数据重新创建一个新的 Fiber 做插入操作 ")]),s._v("\n      "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("const")]),s._v(" newFiber "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("updateFromMap")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("\n        existingChildren"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n        returnFiber"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n        newIdx"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n        newChildren"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),s._v("newIdx"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n        lanes"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n      "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n      "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("if")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("newFiber "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("!==")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("null")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n        \n        "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("if")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("shouldTrackSideEffects"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n          "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("// newFiber.alternate 不为 null，表示是重用的节点，需要将 existingChildren 中重用的节点删除掉")]),s._v("\n          "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("// 遍历结束后 existingChildren 中剩下的节点，则是需要删除的    ")]),s._v("\n          "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("if")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("newFiber"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("alternate "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("!==")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("null")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n            "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("// 在调用 updateFromMap 方法时，会根据 key 取出相对应的 Fiber")]),s._v("\n            "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("// 调用 updateFromMap 方法完成后，对应 key 的 Fiber 值被重用了，所以需要删除 Map 中使用过的 key 对应的值  ")]),s._v("\n            existingChildren"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("delete")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("\n              newFiber"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("key "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("===")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("null")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("?")]),s._v(" newIdx "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v(":")]),s._v(" newFiber"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("key"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n            "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n          "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n        "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n        "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("// 将 newIdx 赋值给 workInProgress 树上的 Fiber 节点的 index 属性，代表当前元素在列表中的位置（下标）")]),s._v("\n        "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("// 判断 current 树上元素的 Index 是否小于 lastPlacedIndex，是则表示该元素需要移动位置，否则表示不需要移动位置。  ")]),s._v("\n        lastPlacedIndex "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("placeChild")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("newFiber"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" lastPlacedIndex"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" newIdx"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n        "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("if")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("previousNewFiber "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("===")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("null")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n          resultingFirstChild "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" newFiber"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n        "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("else")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n          previousNewFiber"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("sibling "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" newFiber"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n        "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n        previousNewFiber "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" newFiber"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n      "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n    "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n    "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("// 节点删除")]),s._v("\n    "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("if")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("shouldTrackSideEffects"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n      "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("// existingChildren 中剩下的 Fiber，表示 current 树上存在，但是 workInProgress 树上不存在的元素")]),s._v("\n      "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("// 将剩下的 Fiber 添加到父 Fiber 节点的 deletions 属性中, ")]),s._v("\n      "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("// 并且在 flags 集合中添加删除标识，在 commit 阶段会将这些元素进行删除")]),s._v("\n      existingChildren"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("forEach")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token parameter"}},[s._v("child")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=>")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("deleteChild")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("returnFiber"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" child"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n    "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n    "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("// 返回列表中的第一个节点")]),s._v("\n    "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("return")]),s._v(" resultingFirstChild"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n  "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n")])]),s._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[s._v("1")]),t("br"),t("span",{staticClass:"line-number"},[s._v("2")]),t("br"),t("span",{staticClass:"line-number"},[s._v("3")]),t("br"),t("span",{staticClass:"line-number"},[s._v("4")]),t("br"),t("span",{staticClass:"line-number"},[s._v("5")]),t("br"),t("span",{staticClass:"line-number"},[s._v("6")]),t("br"),t("span",{staticClass:"line-number"},[s._v("7")]),t("br"),t("span",{staticClass:"line-number"},[s._v("8")]),t("br"),t("span",{staticClass:"line-number"},[s._v("9")]),t("br"),t("span",{staticClass:"line-number"},[s._v("10")]),t("br"),t("span",{staticClass:"line-number"},[s._v("11")]),t("br"),t("span",{staticClass:"line-number"},[s._v("12")]),t("br"),t("span",{staticClass:"line-number"},[s._v("13")]),t("br"),t("span",{staticClass:"line-number"},[s._v("14")]),t("br"),t("span",{staticClass:"line-number"},[s._v("15")]),t("br"),t("span",{staticClass:"line-number"},[s._v("16")]),t("br"),t("span",{staticClass:"line-number"},[s._v("17")]),t("br"),t("span",{staticClass:"line-number"},[s._v("18")]),t("br"),t("span",{staticClass:"line-number"},[s._v("19")]),t("br"),t("span",{staticClass:"line-number"},[s._v("20")]),t("br"),t("span",{staticClass:"line-number"},[s._v("21")]),t("br"),t("span",{staticClass:"line-number"},[s._v("22")]),t("br"),t("span",{staticClass:"line-number"},[s._v("23")]),t("br"),t("span",{staticClass:"line-number"},[s._v("24")]),t("br"),t("span",{staticClass:"line-number"},[s._v("25")]),t("br"),t("span",{staticClass:"line-number"},[s._v("26")]),t("br"),t("span",{staticClass:"line-number"},[s._v("27")]),t("br"),t("span",{staticClass:"line-number"},[s._v("28")]),t("br"),t("span",{staticClass:"line-number"},[s._v("29")]),t("br"),t("span",{staticClass:"line-number"},[s._v("30")]),t("br"),t("span",{staticClass:"line-number"},[s._v("31")]),t("br"),t("span",{staticClass:"line-number"},[s._v("32")]),t("br"),t("span",{staticClass:"line-number"},[s._v("33")]),t("br"),t("span",{staticClass:"line-number"},[s._v("34")]),t("br"),t("span",{staticClass:"line-number"},[s._v("35")]),t("br"),t("span",{staticClass:"line-number"},[s._v("36")]),t("br"),t("span",{staticClass:"line-number"},[s._v("37")]),t("br"),t("span",{staticClass:"line-number"},[s._v("38")]),t("br"),t("span",{staticClass:"line-number"},[s._v("39")]),t("br"),t("span",{staticClass:"line-number"},[s._v("40")]),t("br"),t("span",{staticClass:"line-number"},[s._v("41")]),t("br"),t("span",{staticClass:"line-number"},[s._v("42")]),t("br"),t("span",{staticClass:"line-number"},[s._v("43")]),t("br"),t("span",{staticClass:"line-number"},[s._v("44")]),t("br"),t("span",{staticClass:"line-number"},[s._v("45")]),t("br"),t("span",{staticClass:"line-number"},[s._v("46")]),t("br"),t("span",{staticClass:"line-number"},[s._v("47")]),t("br"),t("span",{staticClass:"line-number"},[s._v("48")]),t("br"),t("span",{staticClass:"line-number"},[s._v("49")]),t("br"),t("span",{staticClass:"line-number"},[s._v("50")]),t("br"),t("span",{staticClass:"line-number"},[s._v("51")]),t("br"),t("span",{staticClass:"line-number"},[s._v("52")]),t("br"),t("span",{staticClass:"line-number"},[s._v("53")]),t("br"),t("span",{staticClass:"line-number"},[s._v("54")]),t("br"),t("span",{staticClass:"line-number"},[s._v("55")]),t("br"),t("span",{staticClass:"line-number"},[s._v("56")]),t("br"),t("span",{staticClass:"line-number"},[s._v("57")]),t("br"),t("span",{staticClass:"line-number"},[s._v("58")]),t("br"),t("span",{staticClass:"line-number"},[s._v("59")]),t("br"),t("span",{staticClass:"line-number"},[s._v("60")]),t("br"),t("span",{staticClass:"line-number"},[s._v("61")]),t("br"),t("span",{staticClass:"line-number"},[s._v("62")]),t("br"),t("span",{staticClass:"line-number"},[s._v("63")]),t("br"),t("span",{staticClass:"line-number"},[s._v("64")]),t("br"),t("span",{staticClass:"line-number"},[s._v("65")]),t("br"),t("span",{staticClass:"line-number"},[s._v("66")]),t("br"),t("span",{staticClass:"line-number"},[s._v("67")]),t("br"),t("span",{staticClass:"line-number"},[s._v("68")]),t("br"),t("span",{staticClass:"line-number"},[s._v("69")]),t("br"),t("span",{staticClass:"line-number"},[s._v("70")]),t("br"),t("span",{staticClass:"line-number"},[s._v("71")]),t("br"),t("span",{staticClass:"line-number"},[s._v("72")]),t("br"),t("span",{staticClass:"line-number"},[s._v("73")]),t("br"),t("span",{staticClass:"line-number"},[s._v("74")]),t("br"),t("span",{staticClass:"line-number"},[s._v("75")]),t("br"),t("span",{staticClass:"line-number"},[s._v("76")]),t("br"),t("span",{staticClass:"line-number"},[s._v("77")]),t("br"),t("span",{staticClass:"line-number"},[s._v("78")]),t("br"),t("span",{staticClass:"line-number"},[s._v("79")]),t("br"),t("span",{staticClass:"line-number"},[s._v("80")]),t("br"),t("span",{staticClass:"line-number"},[s._v("81")]),t("br"),t("span",{staticClass:"line-number"},[s._v("82")]),t("br"),t("span",{staticClass:"line-number"},[s._v("83")]),t("br"),t("span",{staticClass:"line-number"},[s._v("84")]),t("br"),t("span",{staticClass:"line-number"},[s._v("85")]),t("br"),t("span",{staticClass:"line-number"},[s._v("86")]),t("br"),t("span",{staticClass:"line-number"},[s._v("87")]),t("br"),t("span",{staticClass:"line-number"},[s._v("88")]),t("br"),t("span",{staticClass:"line-number"},[s._v("89")]),t("br"),t("span",{staticClass:"line-number"},[s._v("90")]),t("br"),t("span",{staticClass:"line-number"},[s._v("91")]),t("br"),t("span",{staticClass:"line-number"},[s._v("92")]),t("br"),t("span",{staticClass:"line-number"},[s._v("93")]),t("br"),t("span",{staticClass:"line-number"},[s._v("94")]),t("br"),t("span",{staticClass:"line-number"},[s._v("95")]),t("br"),t("span",{staticClass:"line-number"},[s._v("96")]),t("br"),t("span",{staticClass:"line-number"},[s._v("97")]),t("br"),t("span",{staticClass:"line-number"},[s._v("98")]),t("br"),t("span",{staticClass:"line-number"},[s._v("99")]),t("br"),t("span",{staticClass:"line-number"},[s._v("100")]),t("br"),t("span",{staticClass:"line-number"},[s._v("101")]),t("br"),t("span",{staticClass:"line-number"},[s._v("102")]),t("br"),t("span",{staticClass:"line-number"},[s._v("103")]),t("br"),t("span",{staticClass:"line-number"},[s._v("104")]),t("br"),t("span",{staticClass:"line-number"},[s._v("105")]),t("br"),t("span",{staticClass:"line-number"},[s._v("106")]),t("br"),t("span",{staticClass:"line-number"},[s._v("107")]),t("br"),t("span",{staticClass:"line-number"},[s._v("108")]),t("br"),t("span",{staticClass:"line-number"},[s._v("109")]),t("br"),t("span",{staticClass:"line-number"},[s._v("110")]),t("br"),t("span",{staticClass:"line-number"},[s._v("111")]),t("br"),t("span",{staticClass:"line-number"},[s._v("112")]),t("br"),t("span",{staticClass:"line-number"},[s._v("113")]),t("br"),t("span",{staticClass:"line-number"},[s._v("114")]),t("br"),t("span",{staticClass:"line-number"},[s._v("115")]),t("br"),t("span",{staticClass:"line-number"},[s._v("116")]),t("br"),t("span",{staticClass:"line-number"},[s._v("117")]),t("br"),t("span",{staticClass:"line-number"},[s._v("118")]),t("br"),t("span",{staticClass:"line-number"},[s._v("119")]),t("br"),t("span",{staticClass:"line-number"},[s._v("120")]),t("br"),t("span",{staticClass:"line-number"},[s._v("121")]),t("br"),t("span",{staticClass:"line-number"},[s._v("122")]),t("br"),t("span",{staticClass:"line-number"},[s._v("123")]),t("br"),t("span",{staticClass:"line-number"},[s._v("124")]),t("br"),t("span",{staticClass:"line-number"},[s._v("125")]),t("br"),t("span",{staticClass:"line-number"},[s._v("126")]),t("br"),t("span",{staticClass:"line-number"},[s._v("127")]),t("br"),t("span",{staticClass:"line-number"},[s._v("128")]),t("br"),t("span",{staticClass:"line-number"},[s._v("129")]),t("br"),t("span",{staticClass:"line-number"},[s._v("130")]),t("br"),t("span",{staticClass:"line-number"},[s._v("131")]),t("br"),t("span",{staticClass:"line-number"},[s._v("132")]),t("br"),t("span",{staticClass:"line-number"},[s._v("133")]),t("br"),t("span",{staticClass:"line-number"},[s._v("134")]),t("br"),t("span",{staticClass:"line-number"},[s._v("135")]),t("br"),t("span",{staticClass:"line-number"},[s._v("136")]),t("br"),t("span",{staticClass:"line-number"},[s._v("137")]),t("br"),t("span",{staticClass:"line-number"},[s._v("138")]),t("br")])]),t("h3",{attrs:{id:"第一轮遍历"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#第一轮遍历"}},[s._v("#")]),s._v(" 第一轮遍历")]),s._v(" "),t("p",[s._v("从前到后遍历新旧子节点")]),s._v(" "),t("ul",[t("li",[t("strong",[s._v("key 和 type 都相同")]),s._v("，则根据旧 fiber 和新 ReactElement 的 props 生成新子节点 fiber。即， 使用 React element 的数据更新 Fiber 节点上的属性。 "),t("strong",[s._v("复用旧节点，只更新其属性 props")]),s._v("（当然也包含 children）")]),s._v(" "),t("li",[t("strong",[s._v("key 相同，但 type 不同")]),s._v("，将根据新 ReactElement 生成新 fiber，旧 fiber 将被添加到它的父级 fiber 的 deletions 数组中，后续将被移除。"),t("strong",[s._v("创建新节点")]),s._v("，删除旧节点。")]),s._v(" "),t("li",[t("strong",[s._v("key 不同")]),s._v("，结束遍历。")])]),s._v(" "),t("p",[t("img",{attrs:{src:"/blog/images/react/diff1.png",alt:"diff1"}})]),s._v(" "),t("h3",{attrs:{id:"第二轮遍历"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#第二轮遍历"}},[s._v("#")]),s._v(" 第二轮遍历")]),s._v(" "),t("p",[s._v("如果第一轮遍历被提前终止了，意味着还有"),t("strong",[s._v("新 ReactElement")]),s._v(" 或 "),t("strong",[s._v("旧 fiber")]),s._v(" 还"),t("strong",[s._v("未被遍历")]),s._v("。因此会有第二轮遍历去处理以下三种情况：")]),s._v(" "),t("ul",[t("li",[t("p",[s._v("只剩旧子节点")]),s._v(" "),t("ul",[t("li",[s._v("说明多余的 "),t("code",[s._v("oldFiber")]),s._v(" 在这次更新中已经不存在了，所以需要遍历剩下的 oldFiber，依次执行删除操作（"),t("code",[s._v("Fiber.effectTag = Deletion")]),s._v("）")])])]),s._v(" "),t("li",[t("p",[s._v("只剩新子节点")]),s._v(" "),t("ul",[t("li",[s._v("说明老的 DOM 节点都复用了，这时还有新加入的节点，意味着本次更新有新节点插入，我们只需要遍历剩下的 newChildren 依次执行插入操作（"),t("code",[s._v("Fiber.effectTag = Placement")]),s._v("）")])])]),s._v(" "),t("li",[t("p",[s._v("新旧子节点都有剩")]),s._v(" "),t("ul",[t("li",[s._v("说明有节点在这次更新中改变了位置，需要移动节点。由于有节点交换了位置，所以不能再用位置索引对比前后的节点，那么怎样才能将同一个节点在两次更新中对应上呢？这时候就需要用 key 属性了。为了快速的找到 key 对应的 oldFiber，将所有还没处理的 oldFiber 放进以 key 属性为 key，以 Fiber 为 value 的 map，空间换时间。")])])])]),s._v(" "),t("p",[t("img",{attrs:{src:"/blog/images/react/diff2.png",alt:"diff2"}})]),s._v(" "),t("h4",{attrs:{id:"只剩旧子节点"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#只剩旧子节点"}},[s._v("#")]),s._v(" 只剩旧子节点")]),s._v(" "),t("p",[s._v("只剩下旧子节点的处理方法很简单，只需要将剩余的 旧 fiber 放到父 fiber 的 deletions 数组中，这些旧 fiber 对应的 DOM 节点将会在 "),t("strong",[s._v("commit 阶段被移除")]),s._v("。")]),s._v(" "),t("p",[t("img",{attrs:{src:"/blog/images/react/diff3.png",alt:"diff3"}})]),s._v(" "),t("h4",{attrs:{id:"只剩新子节点"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#只剩新子节点"}},[s._v("#")]),s._v(" 只剩新子节点")]),s._v(" "),t("p",[s._v("对于剩余的新子节点，先"),t("strong",[s._v("创建新的 fiber 节点")]),s._v("，然后打上 Placement 标记，我们将在遍历 fiber 树的「归」阶段生成这些新 fiber 对应的 DOM 节点。")]),s._v(" "),t("p",[t("img",{attrs:{src:"/blog/images/react/diff4.png",alt:"diff4"}})]),s._v(" "),t("h4",{attrs:{id:"新旧子节点都有剩"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#新旧子节点都有剩"}},[s._v("#")]),s._v(" 新旧子节点都有剩")]),s._v(" "),t("p",[s._v("由于有节点交换了位置，所以不能再用位置索引对比前后的节点，那么怎样才能将同一个节点在两次更新中对应上呢？这时候就需要用 key 属性了。为了快速的找到 key 对应的 oldFiber，将所有还没处理的 oldFiber 放进以 key 属性为 key，以 Fiber 为 value 的 map，空间换时间。")]),s._v(" "),t("p",[s._v("这种情况下，需要一个快速的方法帮助我们快速找到某个 ReactElement 在上一次渲染时生成的 fiber 节点。因此，我们需要一个 "),t("code",[s._v("existingChildren Map")]),s._v("，这个 Map "),t("strong",[s._v("保存了旧 fiber 的 key 到 旧 fiber 的映射关系")]),s._v("，我们可以"),t("strong",[s._v("通过新的 ReactElement 的 key 快速在这个 Map 中找到对应的旧 fiber")]),s._v("：")]),s._v(" "),t("ul",[t("li",[s._v("能找到，则能"),t("strong",[s._v("复用旧 fiber")]),s._v(" 以生成新 fiber")]),s._v(" "),t("li",[s._v("找不到，证明要"),t("strong",[s._v("生成新的 fiber")]),s._v("，并打上一个 Placement 标志，以便于在 commit 阶段插入该 fiber 对应的 DOM 节点。")])]),s._v(" "),t("p",[s._v("我们还需要找到哪些节点的位置发生了变化。")]),s._v(" "),t("p",[s._v("假设我们有 a、b、c、d 四个节点，它们的位置索引是 0、1、2、3，是一个递增的序列。在更新后，它们顺序发生了变化，变成了 a、c、b、d，那么它们的位置索引变为 0、2、1、3（继续沿用旧的位置索引），不再是一个递增的序列，因为索引 1 移到了 2 的后面（即 b 原本在 c 前面，更新后被移到了 c 后面），破坏了递增的规律。因此，只需要找到那些破坏了索引递增规律的节点，就知道哪些节点的位置发生了变化。那具体要怎么做呢？")]),s._v(" "),t("p",[s._v("其实，旧 fiber 上有 index 属性，index 属性记录了在上一次渲染时该 fiber 所在的位置索引。")]),s._v(" "),t("ul",[t("li",[t("strong",[s._v("oldIndex")]),s._v("：当前可复用节点在旧节点上的位置索引")]),s._v(" "),t("li",[t("strong",[s._v("lastPlacedIndex")]),s._v("：把遍历新子节点过程中访问过的最大 oldIndex。该变量表示当前最后一个可复用节点，对应的 oldFiber 在上一次更新中所在的位置索引。我们通过这个变量判断节点是否需要移动。")])]),s._v(" "),t("p",[s._v("如果 "),t("code",[s._v("oldIndex >= lastPlacedIndex")]),s._v(" 代表该可复用节点不需要移动，并将 "),t("code",[s._v("lastPlacedIndex = oldIndex")]),s._v(";\n如果 "),t("code",[s._v("oldIndex < lastplacedIndex")]),s._v(" 该可复用节点之前插入的位置索引小于这次更新需要插入的位置索引，代表该节点需要向右移动。那么，只要当前新子节点有对应的旧 fiber，且 "),t("code",[s._v("oldIndex < lastPlacedIndex")]),s._v("，就可以认为该新子节点对应的 DOM 节点需要往后移动，并打上一个 Placement 标志，以便于在 commit 阶段识别出这个需要移动 DOM 节点的 fiber。")]),s._v(" "),t("h4",{attrs:{id:"遍历流程"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#遍历流程"}},[s._v("#")]),s._v(" 遍历流程")]),s._v(" "),t("ul",[t("li",[t("p",[s._v("遍历未处理的旧子节点，生成 existingChildren Map")])]),s._v(" "),t("li",[t("p",[s._v("从前到后遍历新子节点")]),s._v(" "),t("ul",[t("li",[s._v("如果能在 existingChildren Map 中找到对应的旧 fiber，根据旧 fiber 生成新 fiber；如果不能，生成新 fiber，并打上 Placement 标志")]),s._v(" "),t("li",[s._v("从 existingChildren Map 中删除已处理的节点")]),s._v(" "),t("li",[s._v("如果新子节点有对应的旧 fiber\n"),t("ul",[t("li",[s._v("当 "),t("code",[s._v("oldIndex < lastPlacedIndex")]),s._v(" 时，给新 fiber 打上 Placement 标志；否则，令 "),t("code",[s._v("lastPlacedIndex = newIndex")])])])]),s._v(" "),t("li",[s._v("如果新子节点没有对应的旧 fiber，创建一个新 fiber 并 打上 Placement 标志")])])]),s._v(" "),t("li",[t("p",[s._v("遍历 existingChildren Map，将 Map 中所有节点添加到父节点的 deletions 数组中")])])]),s._v(" "),t("p",[t("img",{attrs:{src:"/blog/images/react/diff5.png",alt:"diff5"}})]),s._v(" "),t("h3",{attrs:{id:"commit-阶段变更"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#commit-阶段变更"}},[s._v("#")]),s._v(" Commit 阶段变更")]),s._v(" "),t("p",[s._v("DOM 元素类型的 fiber 节点上存有对 DOM 节点的引用，因此在 commit 阶段，深度优先遍历每个新 fiber 节点，对 fiber 节点对应的 DOM 节点做以下变更：")]),s._v(" "),t("ul",[t("li",[s._v("删除 deletions 数组中 fiber 对应的 DOM 节点")]),s._v(" "),t("li",[s._v("如有 Placement 标志，"),t("strong",[s._v("将节点移动到往后第一个没有 Placement 标记的")]),s._v(" "),t("strong",[s._v("fiber")]),s._v(" "),t("strong",[s._v("的")]),s._v(" "),t("strong",[s._v("DOM")]),s._v(" "),t("strong",[s._v("节点之前")]),s._v("。")]),s._v(" "),t("li",[s._v("更新节点。以 DOM 节点为例，在生成 fiber 树的「归」阶段，会找出属性的变更集，在 commit 阶段更新属性。")])]),s._v(" "),t("p",[t("img",{attrs:{src:"/blog/images/react/diff6.png",alt:"diff6"}})]),s._v(" "),t("h2",{attrs:{id:"性能缺陷"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#性能缺陷"}},[s._v("#")]),s._v(" 性能缺陷")]),s._v(" "),t("p",[s._v("React 采用仅右移方案，在大部分从左往右移的业务场景中，得到了较好的性能。但在处理节点左移(前移)，表现就不太乐观。")]),s._v(" "),t("p",[s._v("以下图为例，节点 "),t("code",[s._v("a、b、c、d")]),s._v(" 变为了"),t("code",[s._v("d、a、b、c")]),s._v("，如果我们手动处理这种位置变化，只需要一步：将 d 节点移动到 a 前面。但 React 实际上的做法有三步：将 a、b、c 三个节点依次插入到 d 节点后面。")]),s._v(" "),t("p",[t("img",{attrs:{src:"/blog/images/react/diff7.png",alt:"diff7"}})]),s._v(" "),t("p",[s._v("这是因为遍历完 d 节点后，"),t("code",[s._v("lastPlacedIndex")]),s._v(" 变成了 3，再去遍历 a、b、c、d 时，**"),t("code",[s._v("oldIndex")]),s._v(" 一定小于 "),t("code",[s._v("lastPlacedIndex")]),s._v("**了。")]),s._v(" "),t("p",[s._v("因此，实际编写代码时，应该尽量避免节点往前移动的操作。")]),s._v(" "),t("h2",{attrs:{id:"为什么不用双端-diff"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#为什么不用双端-diff"}},[s._v("#")]),s._v(" 为什么不用双端 Diff")]),s._v(" "),t("p",[s._v("既然 React 对节点往前移动的情况处理得不好，是不是可以在每次遍历的时候，都尝试和旧子节点中最后一个未处理节点做对比，看看能不能匹配上。实际上，Vue2 的 diff 就是这么做的。")]),s._v(" "),t("p",[s._v("Vue 2 的双端 diff 是旧的一组 VNode（旧子节点）和新的一组 VNode（新子节点）进行对比")]),s._v(" "),t("p",[s._v("所谓的「双端」，表示在新旧子节点的数组中，各用两个指针指向头尾节点，在遍历过程中，头尾指针不断靠拢。因此，用 newStartIndex 和 newEndIndex 分别指向新子节点中未处理节点的头尾节点，用 oldStartIndex 和 oldEndIndex 分别指向旧子节点中未处理节点的头尾节点。")]),s._v(" "),t("p",[s._v("现在，我们用「新前」表示新子节点中未处理节点的第一个节点；用「新后」表示新子节点中未处理节点的最后一个节点；「旧前」表示旧子节点中未处理节点的第一个节点；用「旧后」表示旧子节点中未处理节点的最后一个节点。")]),s._v(" "),t("p",[s._v("每遍历到一个节点，就尝试进行双端比较：「新前 vs 旧前」、「新后 vs 旧后」、「新后 vs 旧前」、「新前 vs 旧后」，如果匹配成功，更新双端的指针。比如，新旧子节点通过「新前 vs 旧后」匹配成功，那么 newStartIndex += 1，oldEndIndex -= 1。")]),s._v(" "),t("p",[s._v("如果新旧子节点通过「新后 vs 旧前」匹配成功，还需要将「旧前」对应的 DOM 节点插入到「旧后」对应的 DOM 节点之前。如果新旧子节点通过「新前 vs 旧后」匹配成功，还需要将「旧后」对应的 DOM 节点插入到「旧前」对应的 DOM 节点之前。")]),s._v(" "),t("p",[s._v("如果通过双端比较都没法找到匹配的节点，就需要一个像 React existingChildren Map 的 Map 对象了，在 Vue2 的 diff 中，这个 Map 名字叫做 oldKeyToIdx Map。通过这个 Map，遍历时就可以尝试根据新子节点的 key 去找 oldIndex，查找结果会有两种：")]),s._v(" "),t("ul",[t("li",[t("p",[s._v("找到 oldIndex，即新旧子节点中有相同 key 的节点。")]),s._v(" "),t("ul",[t("li",[s._v("如果 VNode 的 type 是相同的，将旧子节点对应的 DOM 节点插入到「旧前」对应的 DOM 节点之前。")]),s._v(" "),t("li",[s._v("如果 VNode 的 type 是不同的，创建一个新的 DOM 节点，并插入到「旧前」对应的 DOM 节点之前。")])])]),s._v(" "),t("li",[t("p",[s._v("没找 oldIndex，需要根据新子节点（VNode）创建 DOM 元素，并插入到「旧前」对应的 DOM 节点之前。")])])]),s._v(" "),t("p",[s._v("简单来说，第一轮遍历会先尝试比较新旧子节点的双端节点，如果匹配不成功，再尝试在旧子节中找到对应的节点。至于 DOM 节点的移动，需要记住只能移动到「旧前」之前或「旧后」之后。如果更新后节点位置被调到前面了，移动时就需要移到「旧前」之前；如果更新后节点位置被调到后面了，移动时就需要移到「旧后」之后。")]),s._v(" "),t("ul",[t("li",[t("p",[s._v("如果第一轮遍历后，只剩下新子节点（oldStartIndex > oldEndIndex），则根据剩余的新子节点（VNode）创建 DOM 节点，并依次插入到父级 DOM 节点最后。")])]),s._v(" "),t("li",[t("p",[s._v("如果第一轮遍历后，只剩下旧子节点（newStartIndex > newEndIndex），则将剩余旧子节点对应的 DOM 节点依次从父级 DOM 节点中删除。")])])]),s._v(" "),t("p",[s._v("需要注意的是，Vue 在 diff 的过程中，会直接进行节点的更新/新建/删除操作，这点和 React 是不同的。")]),s._v(" "),t("p",[t("img",{attrs:{src:"/blog/images/react/diff8.png",alt:"diff8"}})]),s._v(" "),t("p",[s._v("关于 Vue2 Diff 更详细参考 - "),t("RouterLink",{attrs:{to:"/vue/vue/vue-diff.html"}},[s._v("Vue2 Diff 双端比较")])],1),s._v(" "),t("p",[s._v("React 在源码注释中解释了"),t("strong",[s._v("为什么不使用双端 diff")]),s._v("：")]),s._v(" "),t("p",[s._v("由于双端 diff 需要向前查找节点，但每个 fiber 节点上都没有反向指针，即前一个 fiber 通过 sibling 属性指向后一个 fiber，只能从前往后遍历，而不能反过来（你可以在上文的各个示例图中看到这种实现），因此该算法无法通过双端搜索来进行优化。React 想看下现在用这种方式能走多远，如果这种方式不理想，以后再考虑实现双端 diff。React 认为对于列表反转和需要进行双端搜索的场景是少见的。单链表无法使用双指针，所以无法对算法使用双指针优化。")]),s._v(" "),t("p",[t("a",{attrs:{href:"https://juejin.cn/post/7161063643105198093#heading-23",target:"_blank",rel:"noopener noreferrer"}},[s._v("一文吃透 React 和 Vue 的多节点 diff 原理"),t("OutboundLink")],1)]),s._v(" "),t("p",[t("a",{attrs:{href:"https://juejin.cn/post/6919376064833667080#heading-13",target:"_blank",rel:"noopener noreferrer"}},[s._v("React、Vue2、Vue3的三种Diff算法"),t("OutboundLink")],1)]),s._v(" "),t("p",[t("a",{attrs:{href:"https://mp.weixin.qq.com/s/KCX8xwY563qCAJqaK2H2EA",target:"_blank",rel:"noopener noreferrer"}},[s._v("精读《DOM diff 原理详解》"),t("OutboundLink")],1)]),s._v(" "),t("p",[t("a",{attrs:{href:"https://mp.weixin.qq.com/s/ZBdmcD5F8GLy_q9cfOvbJg",target:"_blank",rel:"noopener noreferrer"}},[s._v("精读《DOM diff 最长上升子序列》"),t("OutboundLink")],1)])])}),[],!1,null,null,null);t.default=e.exports}}]);